{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "regular-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import copy\n",
    "from math import *\n",
    "import random\n",
    "from tensorflow.keras.layers import Dense, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "rocky-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def f_1(x):\n",
    "    return x*sin(6*pi*x)*exp(-1 * x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "unlike-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "\n",
    "data_f1_x = np.array([])\n",
    "data_f1_y = np.array([])\n",
    "\n",
    "for i in range(200):\n",
    "    x_f1 = random.uniform(-1, 1)\n",
    "    y_f1 = f_1(x_f1)\n",
    "    \n",
    "    data_f1_x = np.append(data_f1_x, x_f1)\n",
    "    data_f1_y = np.append(data_f1_y, y_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "necessary-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits\n",
    "\n",
    "data_points = [10, 40, 80, 200]\n",
    "hidden_nodes = [2, 10, 40, 100]\n",
    "\n",
    "M = [[() for i in range(4)] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-johnston",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Implementation\n",
    "\n",
    "for i_ in range(16):\n",
    "    \n",
    "    i = int(i_ / 4)\n",
    "    j = i_ % 4\n",
    "    \n",
    "    num_points = data_points[i]\n",
    "    num_nodes = hidden_nodes[j]\n",
    "    num_train = int(num_points * 0.8)\n",
    "\n",
    "    x = data_f1_x[:num_train]\n",
    "    y = data_f1_y[:num_train]\n",
    "\n",
    "    x_test = data_f1_x[num_train: num_points]\n",
    "    y_test = data_f1_y[num_train: num_points]\n",
    "\n",
    "    num_folds = 10\n",
    "\n",
    "    if i == 0:\n",
    "        num_folds = 2\n",
    "    elif i == 1 or i == 2:\n",
    "        num_folds = 8\n",
    "\n",
    "    avg_training_error = 0\n",
    "    avg_validation_error = 0\n",
    "\n",
    "    for shuffle_count in range(5):\n",
    "\n",
    "        np.random.shuffle(x)\n",
    "        np.random.shuffle(y)\n",
    "\n",
    "        k_fold_avg_training_error = 0\n",
    "        k_fold_avg_validation_error = 0\n",
    "\n",
    "        for validation_index in range(num_folds):\n",
    "\n",
    "            paritioned_x = np.array_split(x, num_folds)\n",
    "            paritioned_y = np.array_split(y, num_folds)\n",
    "\n",
    "            validation_x = np.array(paritioned_x[validation_index])\n",
    "            validation_y = np.array(paritioned_y[validation_index])\n",
    "\n",
    "            training_x = np.delete(paritioned_x, validation_index, axis=0).flatten()\n",
    "            training_y = np.delete(paritioned_y, validation_index, axis=0).flatten()\n",
    "\n",
    "            mlp = keras.models.Sequential()\n",
    "            mlp.add(Dense(num_nodes, activation=\"sigmoid\", input_shape=(1,), kernel_initializer=keras.initializers.RandomNormal(mean=0., stddev=30), bias_initializer=keras.initializers.RandomNormal(mean=0., stddev=10)))\n",
    "            mlp.add(Dense(1, activation='linear'))\n",
    "            mlp.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "            callbacks = [\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    # Stop training when `val_loss` is no longer improving\n",
    "                    monitor=\"val_loss\",\n",
    "                    # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "                    min_delta=0.001,\n",
    "                    # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "                    patience=30,\n",
    "                    verbose=1,\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            h = mlp.fit(x, y, epochs=250, batch_size=10, validation_split=0.1, verbose=0, callbacks=callbacks)\n",
    "            k_fold_avg_training_error += h.history['loss'][-1]\n",
    "            k_fold_avg_validation_error += h.history['val_loss'][-1]\n",
    "\n",
    "        k_fold_avg_training_error = k_fold_avg_training_error / num_folds\n",
    "        k_fold_avg_validation_error = k_fold_avg_validation_error / num_folds\n",
    "\n",
    "        avg_training_error += k_fold_avg_training_error\n",
    "        avg_validation_error += k_fold_avg_validation_error\n",
    "\n",
    "    avg_training_error = avg_training_error / 5\n",
    "    avg_validation_error = avg_validation_error / 5\n",
    "\n",
    "    M[i][j] = ((avg_training_error, avg_validation_error))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
